{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4878,"status":"ok","timestamp":1664804841307,"user":{"displayName":"rna2sec colab","userId":"17382902510584606216"},"user_tz":-180},"id":"c3y7Ug5a2pl6"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1664804841307,"user":{"displayName":"rna2sec colab","userId":"17382902510584606216"},"user_tz":-180},"id":"TV-ZiCNTUCBG"},"outputs":[],"source":["def find_next_date(date, month=True):\n","    if month:\n","        greater_and_equal_to = date + pd.DateOffset(months=1)\n","    else:\n","        greater_and_equal_to = date + pd.DateOffset(days=1)\n","\n","    return greater_and_equal_to\n","\n","def find_users_and_generate_new_dfs(date, next_date):\n","    df_before_date = authorid_date_sentiment_counts[authorid_date_sentiment_counts['created_at'] < date]\n","    df_after_next_date = authorid_date_sentiment_counts[authorid_date_sentiment_counts['created_at'] >= next_date]\n","\n","    df_before_date['before_after'] = ['Before'] * df_before_date.shape[0]\n","    df_after_next_date['before_after'] = ['After'] * df_after_next_date.shape[0]\n","\n","    users_before = df_before_date['author_ids'].values\n","    users_after = df_after_next_date['author_ids'].values\n","\n","    common_users = set(users_before).intersection(users_after)\n","\n","    return common_users, pd.concat([df_before_date, df_after_next_date], axis=0).reset_index(drop=True)\n","\n","def creating_df(date, month=True):\n","    next_date = find_next_date(date, month=month)\n","\n","    unique_users, filtered_df = find_users_and_generate_new_dfs(date, next_date)\n","    average = filtered_df[filtered_df['author_ids'].isin(unique_users)]\n","    average = average.groupby(['author_ids', 'before_after', 'sentiment_labels']).agg({'counts':'sum'}).reset_index()\n","    average = average.pivot_table(index=['author_ids', 'before_after'], columns='sentiment_labels',\n","                                  values='counts', dropna=False).fillna(0).reset_index()\n","    average['positive_ratio'] = average[1].values / (average[1].values + average[0].values)\n","    average = average[['author_ids', 'before_after', 'positive_ratio']].rename_axis(None, axis=1)\n","    return average\n","\n","def create_diff_df(date, month=True):\n","    avrg = creating_df(date, month=month)\n","    avrg = avrg.pivot_table(index='author_ids', values='positive_ratio', columns='before_after').reset_index()\n","    avrg['diff'] = avrg['After'].values - avrg['Before'].values\n","    avrg = avrg.drop(columns=['Before', 'After'])\n","    avrg['date'] = [date] * avrg.shape[0]\n","    return avrg"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from nltk.tokenize import RegexpTokenizer\n","TOKENIZER = RegexpTokenizer(r'\\w+')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dataframes_path = \"/data/processed/data_frames\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["world_data_sentiments_raw = pd.read_parquet(f\"{dataframes_path}/world_data_sentiments_raw.parquet\")\n","author_ids_and_sentiments = pd.read_parquet(f\"{dataframes_path}/author_ids_and_sentiments.parquet\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["world_data_sentiments_raw['created_at'] = pd.to_datetime(world_data_sentiments_raw['created_at'].apply(lambda x: x[:10]))\n","\n","world_data_sentiments_raw = world_data_sentiments_raw[['id', 'created_at', 'Anti', 'Pro']]\n","\n","world_data_sentiments_raw = world_data_sentiments_raw.iloc[np.max(world_data_sentiments_raw.iloc[:, 2:].values, axis=1) >= 0.99, :]\n","world_data_sentiments_raw = world_data_sentiments_raw.drop(columns=['id', 'Anti', 'Pro'])\n","\n","authorid_date_sentiment = pd.concat([world_data_sentiments_raw.reset_index(drop=True),\n","                                     author_ids_and_sentiments.reset_index(drop=True)], axis=1)\n","\n","# save the dataframe\n","authorid_date_sentiment.to_parquet(f\"{dataframes_path}/authorid_date_sentiment.parquet\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del world_data_sentiments_raw, author_ids_and_sentiments"]},{"cell_type":"markdown","metadata":{},"source":["### Author id - Date - Sentiment - Tweet Counts"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["authorid_tweetcount = authorid_date_sentiment.value_counts(['author_ids']).reset_index(name='counts')\n","more_than_2_tweets = set(authorid_tweetcount[authorid_tweetcount['counts'] != 1]['author_ids'].values)\n","\n","# removing people who have only a single tweet\n","authorid_date_sentiment = authorid_date_sentiment[authorid_date_sentiment['author_ids'].isin(more_than_2_tweets)].reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["authorid_date_sentiment_counts = authorid_date_sentiment.value_counts().reset_index(name='counts')\n","authorid_date_sentiment_counts.to_parquet(f\"{dataframes_path}/authorid_date_sentiment_counts.parquet\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"xUIQqi6XAl7A"},"source":["### Daily"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":571},"executionInfo":{"elapsed":19946,"status":"error","timestamp":1664804520086,"user":{"displayName":"rna2sec colab","userId":"17382902510584606216"},"user_tz":-180},"id":"uT4XyT5jgmpO","outputId":"692c5f37-840d-4642-8014-2ca03ce131b5"},"outputs":[],"source":["unique_dates = np.sort(authorid_date_sentiment_counts['created_at'].unique())[1:-1]\n","diff_dfs = []\n","\n","for date in tqdm(pd.to_datetime(unique_dates)):\n","    diff_dfs.append(create_diff_df(date, month=False))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a77VPIYXFKzj"},"outputs":[],"source":["with open(f'{dataframes_path}/diff_dfs.pkl', 'wb') as f:\n","    pickle.dump(diff_dfs, f)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNHlPtHeH6JQ/yZLOPf+lD6","collapsed_sections":[],"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
