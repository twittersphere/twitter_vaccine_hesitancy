{"cells":[{"cell_type":"markdown","metadata":{"id":"hv0cDbOIQ96V"},"source":["# Importing Required Modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qt71BgEqpv-f"},"outputs":[],"source":["from nltk.tokenize import RegexpTokenizer\n","TOKENIZER = RegexpTokenizer(r'\\w+')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qF_cYhJcYUe4"},"outputs":[],"source":["import os\n","import torch\n","import pickle\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from sklearn.utils import class_weight\n","from sklearn.metrics import classification_report\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.model_selection import train_test_split\n","from simpletransformers.classification import ClassificationModel\n","from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xCw3M_VerGCL"},"outputs":[],"source":["device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"yEB9kyBXoXgQ"},"source":["# Class and functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TbkgKWmc7_4"},"outputs":[],"source":["class Model:\n","    def __init__(self, model_name=None, class_weight=None, model=None, model_args=None, patience=None):\n","        if model:\n","            self.model = model\n","        else:\n","            self.model = ClassificationModel(\n","                \"bert\",\n","                model_name,\n","                use_cuda=True,\n","                num_labels=2,\n","                weight=class_weight,\n","                args=model_args,\n","                cuda_device=0\n","            )\n","        self.patience = patience\n","        self.range = 0\n","\n","    def fit(self, train_df, val_df=None, acc=accuracy_score):\n","        self.model.train_model(train_df, acc=acc)\n","\n","    def predict(self, X: list):\n","        return self.model.predict(X)[0]\n","    \n","    def evaluate_model(self, y_true, y_pred):\n","        return f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred)\n","\n","    def early_stopping(self, train_acc, val_acc):\n","        range = train_acc - val_acc\n","        if range > self.range:\n","            self.patience -= 1\n","            self.range = range\n","\n","    def classification_report(self, y_true, y_pred):\n","        return classification_report(y_true, y_pred)\n","\n","    def save_model(self, output_dir):\n","        with open(output_dir, 'wb') as f:\n","            pickle.dump(self.model, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ErwUrFm8n1Ss"},"outputs":[],"source":["def find_scores(y_true, y_pred):\n","    return f1_score(y_true, y_pred, average='macro'), accuracy_score(y_true, y_pred), balanced_accuracy_score(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zKpcfbdbeJtk"},"outputs":[],"source":["def create_auto_model(model_name, model_args, class_weight):\n","    model = ClassificationModel(\n","                \"bert\",\n","                model_name,\n","                use_cuda=True,\n","                num_labels=3,\n","                weight=class_weight,\n","                args=model_args,\n","                cuda_device=0\n","            )\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"QtkWyWjaomos"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ah-iYBCsg_56"},"outputs":[],"source":["ids_and_labels_path = \"/data/raw/crowdbreaks_data/crowdbreaks_tweet_ids_and_labels.csv\"\n","tweets_path = \"/data/raw/crowdbreaks_data/crowdbreaks_tweets.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zp6tL1crhbz0"},"outputs":[],"source":["ids_and_labels = pd.read_csv(ids_and_labels_path)\n","tweets = pd.read_csv(tweets_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGPJmliRsms5"},"outputs":[],"source":["tweet_and_label = ids_and_labels.join(tweets.rename(columns={'id':'tweet_id'}).set_index('tweet_id'), on='tweet_id', rsuffix='_')\n","tweet_and_label = tweet_and_label.dropna().drop(columns=['label_'])\n","tweet_and_label = tweet_and_label[tweet_and_label['agreement'] > 0.66].reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"twGbrN8BovI1"},"outputs":[],"source":["mapping = {0:0, 1:1, -1:2}\n","tweet_and_label['label'] = tweet_and_label['label'].map(mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VHyooqUU0JM-"},"outputs":[],"source":["agreement1 = tweet_and_label[tweet_and_label['agreement'] == 1.0].reset_index(drop=True)\n","agreement66 = tweet_and_label[(tweet_and_label['agreement'] >= 0.66) & (tweet_and_label['agreement'] < 1.0)].reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"_-1IAjk7h2cf"},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXhCH7Oqv_Ki"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(agreement1['text'].values,\n","                                                    agreement1['label'].astype('int').values,\n","                                                    test_size=int(tweet_and_label.shape[0] * 0.2), random_state=42,\n","                                                    stratify = agreement1['label'].astype('int').values)\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test,\n","                                                    test_size=0.5, random_state=42,\n","                                                    stratify = y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhlkfLRjwdBh"},"outputs":[],"source":["X_train = np.concatenate([X_train, agreement66['text'].values])\n","y_train = np.concatenate([y_train, agreement66['label'].values])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Qf9_s39vlyN"},"outputs":[],"source":["df_train = pd.DataFrame(np.concatenate([X_train.reshape((-1, 1)), y_train.reshape((-1, 1))], axis=1),\n","                                      columns=['text', 'labels'])\n","df_test = pd.DataFrame(np.concatenate([X_test.reshape((-1, 1)), y_test.reshape((-1, 1))], axis=1),\n","                                      columns=['text', 'labels'])\n","df_val = pd.DataFrame(np.concatenate([X_val.reshape((-1, 1)), y_val.reshape((-1, 1))], axis=1),\n","                                      columns=['text', 'labels'])"]},{"cell_type":"markdown","metadata":{"id":"H2PijLdRR452"},"source":["# Fine-Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gq8Tldi6oeEO"},"outputs":[],"source":["model_args = {\n","    \"use_early_stopping\": True,\n","    \"early_stopping_patience\": 5,\n","    \"fp16\": False,\n","    \"num_train_epochs\": 20,\n","    'overwrite_output_dir': True,\n","    'learning_rate': 1e-5,\n","    \"save_steps\": -1,\n","    \"evaluate_during_training\": True,\n","    \"early_stopping_consider_epochs\": True,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vghguH9wmede"},"outputs":[],"source":["output_dir = \"/models/sentiment_models\"\n","y_preds_dir = \"/preds\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"og9IWhUL3IFr"},"outputs":[],"source":["if not os.path.exists(output_dir):\n","    os.mkdir(output_dir)\n","if not os.path.exists(y_preds_dir):\n","    os.mkdir(y_preds_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HGi6T9G8ZFjd"},"outputs":[],"source":["weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ou6l1h_uHIBy"},"outputs":[],"source":["hyper_parameter_tuning = {\"learning_rate\":[1e-3, 1e-4, 1e-5],\n","               \"adam_epsilon\": [1e-7, 1e-8, 1e-9],\n","               \"weight\":[weights.tolist(), (weights**2).tolist()],\n","               \"max_seq_length\": [128, 64],\n","               \"weight_decay\":[0, 0.01, 0.0001]}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBxrFn1Zn1K_"},"outputs":[],"source":["model_name = \"digitalepidemiologylab/covid-twitter-bert-v2\"\n","best_scores = [0, 0, 0]\n","all_best = [0, 0, 0]\n","\n","grid_search = list(ParameterGrid(hyper_parameter_tuning))\n","\n","for value in tqdm(grid_search):\n","    for k, v in value.items():\n","        if k != \"weight\":\n","            model_args[k] = v\n","\n","    model = create_auto_model(model_name, model_args, value['weight'])\n","    model.train_model(df_train, eval_df=df_val, acc=accuracy_score)\n","\n","    result, model_outputs, wrong_predictions = model.eval_model(df_test)\n","    y_pred = np.argmax(model_outputs, axis=1)\n","\n","    scores = find_scores(df_test['labels'].values.astype(int), y_pred)\n","    \n","    if scores[0] > all_best[0] and scores[1] > all_best[1] and scores[2] > all_best[2]:\n","        all_best[0] = scores[0]\n","        all_best[1] = scores[1]\n","        all_best[2] = scores[2]\n","        with open(f\"{output_dir}/best_model.db\", 'wb') as f:\n","            pickle.dump(model, f)\n","\n","        np.save(f\"{y_preds_dir}/best_model_y_pred.npy\", y_pred)\n","\n","    if scores[0] > best_scores[0]:\n","        best_scores[0] = scores[0]\n","        with open(f\"{output_dir}/best_f1.db\", 'wb') as f:\n","            pickle.dump(model, f)\n","\n","        np.save(f\"{y_preds_dir}/best_f1_y_pred.npy\", y_pred)\n","\n","    if scores[1] > best_scores[1]:\n","        best_scores[1] = scores[1]\n","        with open(f\"{output_dir}/best_acc.db\", 'wb') as f:\n","            pickle.dump(model, f)\n","\n","        np.save(f\"{y_preds_dir}/best_acc_y_pred.npy\", y_pred)\n","\n","    if scores[2] > best_scores[2]:\n","        best_scores[2] = scores[2]\n","        with open(f\"{output_dir}/best_balanced_acc.db\", 'wb') as f:\n","            pickle.dump(model, f)\n","\n","        np.save(f\"{y_preds_dir}/best_balanced_acc_y_pred.npy\", y_pred)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOCwxa6/VKEcvXAk350QBHC","collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
